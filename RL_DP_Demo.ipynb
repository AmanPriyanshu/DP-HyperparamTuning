{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL-DP-Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7WP13/xLVg0/PkN/EIgwo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmanPriyanshu/DP-HyperparamTuning/blob/main/RL_DP_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5E4oLWCcJSd"
      },
      "source": [
        "# Demo for RL-DP-Project:\n",
        "\n",
        "## SET-UP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgxkz13IX_W9",
        "outputId": "1bf1aa0f-383c-4819-9a4d-67dc78eacee8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g0ts-lKYMXG",
        "outputId": "f8b72af3-eb94-4537-b89b-bbffb9fbb81c"
      },
      "source": [
        "!git clone https://github.com/AmanPriyanshu/DP-HyperparamTuning.git ./RL_DP_Project"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into './RL_DP_Project'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/53)\u001b[K\rremote: Counting objects:   3% (2/53)\u001b[K\rremote: Counting objects:   5% (3/53)\u001b[K\rremote: Counting objects:   7% (4/53)\u001b[K\rremote: Counting objects:   9% (5/53)\u001b[K\rremote: Counting objects:  11% (6/53)\u001b[K\rremote: Counting objects:  13% (7/53)\u001b[K\rremote: Counting objects:  15% (8/53)\u001b[K\rremote: Counting objects:  16% (9/53)\u001b[K\rremote: Counting objects:  18% (10/53)\u001b[K\rremote: Counting objects:  20% (11/53)\u001b[K\rremote: Counting objects:  22% (12/53)\u001b[K\rremote: Counting objects:  24% (13/53)\u001b[K\rremote: Counting objects:  26% (14/53)\u001b[K\rremote: Counting objects:  28% (15/53)\u001b[K\rremote: Counting objects:  30% (16/53)\u001b[K\rremote: Counting objects:  32% (17/53)\u001b[K\rremote: Counting objects:  33% (18/53)\u001b[K\rremote: Counting objects:  35% (19/53)\u001b[K\rremote: Counting objects:  37% (20/53)\u001b[K\rremote: Counting objects:  39% (21/53)\u001b[K\rremote: Counting objects:  41% (22/53)\u001b[K\rremote: Counting objects:  43% (23/53)\u001b[K\rremote: Counting objects:  45% (24/53)\u001b[K\rremote: Counting objects:  47% (25/53)\u001b[K\rremote: Counting objects:  49% (26/53)\u001b[K\rremote: Counting objects:  50% (27/53)\u001b[K\rremote: Counting objects:  52% (28/53)\u001b[K\rremote: Counting objects:  54% (29/53)\u001b[K\rremote: Counting objects:  56% (30/53)\u001b[K\rremote: Counting objects:  58% (31/53)\u001b[K\rremote: Counting objects:  60% (32/53)\u001b[K\rremote: Counting objects:  62% (33/53)\u001b[K\rremote: Counting objects:  64% (34/53)\u001b[K\rremote: Counting objects:  66% (35/53)\u001b[K\rremote: Counting objects:  67% (36/53)\u001b[K\rremote: Counting objects:  69% (37/53)\u001b[K\rremote: Counting objects:  71% (38/53)\u001b[K\rremote: Counting objects:  73% (39/53)\u001b[K\rremote: Counting objects:  75% (40/53)\u001b[K\rremote: Counting objects:  77% (41/53)\u001b[K\rremote: Counting objects:  79% (42/53)\u001b[K\rremote: Counting objects:  81% (43/53)\u001b[K\rremote: Counting objects:  83% (44/53)\u001b[K\rremote: Counting objects:  84% (45/53)\u001b[K\rremote: Counting objects:  86% (46/53)\u001b[K\rremote: Counting objects:  88% (47/53)\u001b[K\rremote: Counting objects:  90% (48/53)\u001b[K\rremote: Counting objects:  92% (49/53)\u001b[K\rremote: Counting objects:  94% (50/53)\u001b[K\rremote: Counting objects:  96% (51/53)\u001b[K\rremote: Counting objects:  98% (52/53)\u001b[K\rremote: Counting objects: 100% (53/53)\u001b[K\rremote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects:   2% (1/37)\u001b[K\rremote: Compressing objects:   5% (2/37)\u001b[K\rremote: Compressing objects:   8% (3/37)\u001b[K\rremote: Compressing objects:  10% (4/37)\u001b[K\rremote: Compressing objects:  13% (5/37)\u001b[K\rremote: Compressing objects:  16% (6/37)\u001b[K\rremote: Compressing objects:  18% (7/37)\u001b[K\rremote: Compressing objects:  21% (8/37)\u001b[K\rremote: Compressing objects:  24% (9/37)\u001b[K\rremote: Compressing objects:  27% (10/37)\u001b[K\rremote: Compressing objects:  29% (11/37)\u001b[K\rremote: Compressing objects:  32% (12/37)\u001b[K\rremote: Compressing objects:  35% (13/37)\u001b[K\rremote: Compressing objects:  37% (14/37)\u001b[K\rremote: Compressing objects:  40% (15/37)\u001b[K\rremote: Compressing objects:  43% (16/37)\u001b[K\rremote: Compressing objects:  45% (17/37)\u001b[K\rremote: Compressing objects:  48% (18/37)\u001b[K\rremote: Compressing objects:  51% (19/37)\u001b[K\rremote: Compressing objects:  54% (20/37)\u001b[K\rremote: Compressing objects:  56% (21/37)\u001b[K\rremote: Compressing objects:  59% (22/37)\u001b[K\rremote: Compressing objects:  62% (23/37)\u001b[K\rremote: Compressing objects:  64% (24/37)\u001b[K\rremote: Compressing objects:  67% (25/37)\u001b[K\rremote: Compressing objects:  70% (26/37)\u001b[K\rremote: Compressing objects:  72% (27/37)\u001b[K\rremote: Compressing objects:  75% (28/37)\u001b[K\rremote: Compressing objects:  78% (29/37)\u001b[K\rremote: Compressing objects:  81% (30/37)\u001b[K\rremote: Compressing objects:  83% (31/37)\u001b[K\rremote: Compressing objects:  86% (32/37)\u001b[K\rremote: Compressing objects:  89% (33/37)\u001b[K\rremote: Compressing objects:  91% (34/37)\u001b[K\rremote: Compressing objects:  94% (35/37)\u001b[K\rremote: Compressing objects:  97% (36/37)\u001b[K\rremote: Compressing objects: 100% (37/37)\u001b[K\rremote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "Unpacking objects:   1% (1/53)   \rUnpacking objects:   3% (2/53)   \rUnpacking objects:   5% (3/53)   \rUnpacking objects:   7% (4/53)   \rUnpacking objects:   9% (5/53)   \rUnpacking objects:  11% (6/53)   \rUnpacking objects:  13% (7/53)   \rUnpacking objects:  15% (8/53)   \rUnpacking objects:  16% (9/53)   \rUnpacking objects:  18% (10/53)   \rUnpacking objects:  20% (11/53)   \rUnpacking objects:  22% (12/53)   \rUnpacking objects:  24% (13/53)   \rUnpacking objects:  26% (14/53)   \rUnpacking objects:  28% (15/53)   \rUnpacking objects:  30% (16/53)   \rUnpacking objects:  32% (17/53)   \rUnpacking objects:  33% (18/53)   \rUnpacking objects:  35% (19/53)   \rremote: Total 53 (delta 17), reused 44 (delta 11), pack-reused 0\u001b[K\n",
            "Unpacking objects:  37% (20/53)   \rUnpacking objects:  39% (21/53)   \rUnpacking objects:  41% (22/53)   \rUnpacking objects:  43% (23/53)   \rUnpacking objects:  45% (24/53)   \rUnpacking objects:  47% (25/53)   \rUnpacking objects:  49% (26/53)   \rUnpacking objects:  50% (27/53)   \rUnpacking objects:  52% (28/53)   \rUnpacking objects:  54% (29/53)   \rUnpacking objects:  56% (30/53)   \rUnpacking objects:  58% (31/53)   \rUnpacking objects:  60% (32/53)   \rUnpacking objects:  62% (33/53)   \rUnpacking objects:  64% (34/53)   \rUnpacking objects:  66% (35/53)   \rUnpacking objects:  67% (36/53)   \rUnpacking objects:  69% (37/53)   \rUnpacking objects:  71% (38/53)   \rUnpacking objects:  73% (39/53)   \rUnpacking objects:  75% (40/53)   \rUnpacking objects:  77% (41/53)   \rUnpacking objects:  79% (42/53)   \rUnpacking objects:  81% (43/53)   \rUnpacking objects:  83% (44/53)   \rUnpacking objects:  84% (45/53)   \rUnpacking objects:  86% (46/53)   \rUnpacking objects:  88% (47/53)   \rUnpacking objects:  90% (48/53)   \rUnpacking objects:  92% (49/53)   \rUnpacking objects:  94% (50/53)   \rUnpacking objects:  96% (51/53)   \rUnpacking objects:  98% (52/53)   \rUnpacking objects: 100% (53/53)   \rUnpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbVvSy_6cbLL"
      },
      "source": [
        "## Importing Everything:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOLdsmkkchpL",
        "outputId": "bb1fcf8a-a260-46ed-af08-7c1033174b21"
      },
      "source": [
        "!pip install opacus"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opacus\n",
            "  Downloading opacus-0.14.0-py3-none-any.whl (114 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▉                             | 10 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 20 kB 27.6 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 30 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 40 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 92 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 114 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from opacus) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from opacus) (1.9.0+cu102)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.7/dist-packages (from opacus) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->opacus) (3.7.4.3)\n",
            "Installing collected packages: opacus\n",
            "Successfully installed opacus-0.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0Oe4TMyceQz"
      },
      "source": [
        "from opacus import PrivacyEngine\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import os\n",
        "from sklearn.datasets import make_classification\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L_OUEmxcyMU"
      },
      "source": [
        "## Reading the Data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2g9fg1ec1Aj"
      },
      "source": [
        "class ClassificationDataset(torch.utils.data.Dataset):\n",
        "\tdef __init__(self, x, y):\n",
        "\t\tself.x = x\n",
        "\t\tself.y = y\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.x)\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\treturn torch.from_numpy(self.x[idx].astype(np.float32)), torch.from_numpy(np.array([self.y[idx]]).astype(np.float32))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn1xnKAzc-iK"
      },
      "source": [
        "def load_sklearn(val_split=0.2):\n",
        "\tx, y = make_classification(n_samples=4000, n_features=8, n_informative=2, n_redundant=2, n_classes=2, n_clusters_per_class=2, flip_y=0.15, class_sep=1.5, hypercube=True, shift=0.0, shuffle=True, random_state=0)\n",
        "\ttrain_x, train_y, test_x, test_y = x[:int((1-val_split)*len(x))], y[:int((1-val_split)*len(x))], x[int((1-val_split)*len(x)):], y[int((1-val_split)*len(x)):]\n",
        "\treturn train_x, train_y, test_x, test_y"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiwRAHtldDiK"
      },
      "source": [
        "def load_dataset():\n",
        "\ttrain_x, train_y, test_x, test_y = load_sklearn()\n",
        "\ttrain_dataset = ClassificationDataset(train_x, train_y)\n",
        "\ttest_dataset = ClassificationDataset(test_x, test_y)\n",
        "\treturn train_dataset, test_dataset"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAy7OJJ1dYmr",
        "outputId": "e0bface2-8608-4a2e-cf6d-8e2fe346cd46"
      },
      "source": [
        "train_dataset, test_dataset = load_dataset()\n",
        "print(\"Training:\", type(train_dataset), \"Size:\", len(train_dataset))\n",
        "print(\"Testing:\", type(test_dataset), \"Size:\", len(test_dataset))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: <class '__main__.ClassificationDataset'> Size: 3200\n",
            "Testing: <class '__main__.ClassificationDataset'> Size: 800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pejgswmcRl6"
      },
      "source": [
        "## Creating a Torch-Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5F6xHuSYjqI"
      },
      "source": [
        "def get_model():\n",
        "\tmodel = torch.nn.Sequential(\n",
        "\t\t\ttorch.nn.Linear(8, 4),\n",
        "\t\t\ttorch.nn.ReLU(),\n",
        "\t\t\ttorch.nn.Linear(4, 1),\n",
        "\t\t\ttorch.nn.Sigmoid(),\n",
        "\t\t)\n",
        "\treturn model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBCtQwrddkyj",
        "outputId": "85243dc2-210f-443e-d139-de3e083bcf16"
      },
      "source": [
        "print(get_model())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=8, out_features=4, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=4, out_features=1, bias=True)\n",
            "  (3): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_2J3U7zd9Ly"
      },
      "source": [
        "## Loading our Algorithms:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBvIABoKeCOq"
      },
      "source": [
        "from RL_DP_Project.experiment.train_single_model import Experiment\n",
        "from RL_DP_Project.algorithms.bayesian_optimization import Bayesian\n",
        "from RL_DP_Project.algorithms.grid_search_algorithm import GridSearch\n",
        "from RL_DP_Project.algorithms.evolutionary_optimization import EvolutionaryOptimization\n",
        "from RL_DP_Project.algorithms.reinforcement_learning_optimization import RLOptimization"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mngh93AkdtnB"
      },
      "source": [
        "## Running A DP-Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc4-i3IPdlZV"
      },
      "source": [
        "def run_sample():\n",
        "\tcriterion = torch.nn.BCELoss()\n",
        "\ttrain_dataset, test_dataset = load_dataset()\n",
        "\te = Experiment(get_model, criterion, train_dataset, test_dataset)\n",
        "\tresults = e.run_experiment(1, 0.001)\n",
        "\tprint()\n",
        "\tprint(\"RESULTS:\")\n",
        "\t_ = [print(key+\":\", round(item, 4)) for key, item in results.items()]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pmKVQT-ePnI",
        "outputId": "417f7dcc-d782-49fb-8f68-cb251dfc5626"
      },
      "source": [
        "run_sample()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'type': 'training', 'epoch': 1, 'loss': 0.69, 'acc': 0.56}: 100%|██████████| 400/400 [00:04<00:00, 83.70it/s]\n",
            "{'type': 'testing', 'epoch': 1, 'loss': 0.6925, 'acc': 0.5537}: 100%|██████████| 100/100 [00:00<00:00, 216.89it/s]\n",
            "{'type': 'training', 'epoch': 2, 'loss': 0.6755, 'acc': 0.5856}: 100%|██████████| 400/400 [00:04<00:00, 81.59it/s]\n",
            "{'type': 'testing', 'epoch': 2, 'loss': 0.6776, 'acc': 0.5787}: 100%|██████████| 100/100 [00:00<00:00, 203.11it/s]\n",
            "{'type': 'training', 'epoch': 3, 'loss': 0.6602, 'acc': 0.6125}: 100%|██████████| 400/400 [00:04<00:00, 84.09it/s]\n",
            "{'type': 'testing', 'epoch': 3, 'loss': 0.6614, 'acc': 0.5988}: 100%|██████████| 100/100 [00:00<00:00, 187.62it/s]\n",
            "{'type': 'training', 'epoch': 4, 'loss': 0.6436, 'acc': 0.6347}: 100%|██████████| 400/400 [00:04<00:00, 81.83it/s]\n",
            "{'type': 'testing', 'epoch': 4, 'loss': 0.6441, 'acc': 0.6162}: 100%|██████████| 100/100 [00:00<00:00, 153.76it/s]\n",
            "{'type': 'training', 'epoch': 5, 'loss': 0.6252, 'acc': 0.6613}: 100%|██████████| 400/400 [00:04<00:00, 82.53it/s]\n",
            "{'type': 'testing', 'epoch': 5, 'loss': 0.6247, 'acc': 0.6488}: 100%|██████████| 100/100 [00:00<00:00, 161.63it/s]\n",
            "{'type': 'training', 'epoch': 6, 'loss': 0.6049, 'acc': 0.6934}: 100%|██████████| 400/400 [00:04<00:00, 81.64it/s]\n",
            "{'type': 'testing', 'epoch': 6, 'loss': 0.6032, 'acc': 0.6813}: 100%|██████████| 100/100 [00:00<00:00, 252.15it/s]\n",
            "{'type': 'training', 'epoch': 7, 'loss': 0.5826, 'acc': 0.7275}: 100%|██████████| 400/400 [00:04<00:00, 85.67it/s]\n",
            "{'type': 'testing', 'epoch': 7, 'loss': 0.5796, 'acc': 0.7388}: 100%|██████████| 100/100 [00:00<00:00, 179.01it/s]\n",
            "{'type': 'training', 'epoch': 8, 'loss': 0.5577, 'acc': 0.7741}: 100%|██████████| 400/400 [00:04<00:00, 86.47it/s]\n",
            "{'type': 'testing', 'epoch': 8, 'loss': 0.5532, 'acc': 0.785}: 100%|██████████| 100/100 [00:00<00:00, 179.24it/s]\n",
            "{'type': 'training', 'epoch': 9, 'loss': 0.5329, 'acc': 0.8078}: 100%|██████████| 400/400 [00:04<00:00, 82.84it/s]\n",
            "{'type': 'testing', 'epoch': 9, 'loss': 0.5273, 'acc': 0.8263}: 100%|██████████| 100/100 [00:00<00:00, 183.07it/s]\n",
            "{'type': 'training', 'epoch': 10, 'loss': 0.5069, 'acc': 0.8359}: 100%|██████████| 400/400 [00:04<00:00, 84.69it/s]\n",
            "{'type': 'testing', 'epoch': 10, 'loss': 0.4997, 'acc': 0.8363}: 100%|██████████| 100/100 [00:00<00:00, 175.45it/s]\n",
            "{'type': 'training', 'epoch': 11, 'loss': 0.4815, 'acc': 0.8544}: 100%|██████████| 400/400 [00:04<00:00, 86.02it/s]\n",
            "{'type': 'testing', 'epoch': 11, 'loss': 0.4737, 'acc': 0.85}: 100%|██████████| 100/100 [00:00<00:00, 233.66it/s]\n",
            "{'type': 'training', 'epoch': 12, 'loss': 0.458, 'acc': 0.8625}: 100%|██████████| 400/400 [00:04<00:00, 84.24it/s]\n",
            "{'type': 'testing', 'epoch': 12, 'loss': 0.4502, 'acc': 0.865}: 100%|██████████| 100/100 [00:00<00:00, 148.00it/s]\n",
            "{'type': 'training', 'epoch': 13, 'loss': 0.4361, 'acc': 0.8706}: 100%|██████████| 400/400 [00:04<00:00, 87.64it/s]\n",
            "{'type': 'testing', 'epoch': 13, 'loss': 0.4269, 'acc': 0.8712}: 100%|██████████| 100/100 [00:00<00:00, 209.45it/s]\n",
            "{'type': 'training', 'epoch': 14, 'loss': 0.4156, 'acc': 0.8762}: 100%|██████████| 400/400 [00:04<00:00, 82.77it/s]\n",
            "{'type': 'testing', 'epoch': 14, 'loss': 0.4059, 'acc': 0.8775}: 100%|██████████| 100/100 [00:00<00:00, 181.34it/s]\n",
            "{'type': 'training', 'epoch': 15, 'loss': 0.3983, 'acc': 0.8809}: 100%|██████████| 400/400 [00:04<00:00, 89.52it/s]\n",
            "{'type': 'testing', 'epoch': 15, 'loss': 0.3892, 'acc': 0.8862}: 100%|██████████| 100/100 [00:00<00:00, 199.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "RESULTS:\n",
            "eps: 1.2102\n",
            "train_loss: 0.3983\n",
            "val_loss: 0.3892\n",
            "train_acc: 0.8809\n",
            "val_acc: 0.8862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LvTqjrIfbh5"
      },
      "source": [
        "## Creating our Reward Function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raP_BobKeRNe"
      },
      "source": [
        "def calculate_reward(eps, train_loss, val_loss, alpha_u=0.5, alpha_p=0.5):\n",
        "\treturn alpha_p*np.exp(-(eps)) + alpha_u*np.exp(-(val_loss))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1LuhQZrgEWB"
      },
      "source": [
        "## Creating Functions to Run Optimizers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeM06-21gI50"
      },
      "source": [
        "def run_grid_search():\n",
        "\tcriterion = torch.nn.BCELoss()\n",
        "\ttrain_dataset, test_dataset = load_dataset()\n",
        "\te = Experiment(get_model, criterion, train_dataset, test_dataset)\n",
        "\tgs = GridSearch(e.run_experiment, calculate_reward, 10, search_space_nm=[2, 5], search_space_lr=[0.001, 0.05])\n",
        "\tprogress = gs.run()\n",
        "\treturn progress"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJRL65p-gBHx"
      },
      "source": [
        "def run_bayesian():\n",
        "\tcriterion = torch.nn.BCELoss()\n",
        "\ttrain_dataset, test_dataset = load_dataset()\n",
        "\te = Experiment(get_model, criterion, train_dataset, test_dataset)\n",
        "\tb = Bayesian(e.run_experiment, calculate_reward, 100, search_space_nm=[2, 5], search_space_lr=[0.001, 0.05])\n",
        "\tprogress = b.run()\n",
        "\treturn progress"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV1sv3QngLnW"
      },
      "source": [
        "def run_evolutionary_optimization():\n",
        "\tcriterion = torch.nn.BCELoss()\n",
        "\ttrain_dataset, test_dataset = load_dataset()\n",
        "\te = Experiment(get_model, criterion, train_dataset, test_dataset)\n",
        "\teo = EvolutionaryOptimization(e.run_experiment, calculate_reward, 10, search_space_nm=[2, 5], search_space_lr=[0.001, 0.05])\n",
        "\tprogress = eo.run()\n",
        "\treturn progress"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB33mk39gN7O"
      },
      "source": [
        "def run_reinforcement_learning_optimization():\n",
        "\tcriterion = torch.nn.BCELoss()\n",
        "\ttrain_dataset, test_dataset = load_dataset()\n",
        "\te = Experiment(get_model, criterion, train_dataset, test_dataset)\n",
        "\trl = RLOptimization(e.run_experiment, calculate_reward, 10, search_space_nm=[2, 5], search_space_lr=[0.001, 0.05])\n",
        "\tprogress = rl.run()\n",
        "\treturn progress"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIJVRJllgW-p"
      },
      "source": [
        "## Running Each Optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kXYa9vygQ9u",
        "outputId": "1843b3a1-0282-4e62-8a85-72c7fd0b046e"
      },
      "source": [
        "gs_progress = run_grid_search()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [23:36<00:00, 14.17s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZxGDKoKgeR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f555a2-0b28-477d-cee8-334d42a10fe6"
      },
      "source": [
        "bo_progress = run_bayesian()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [22:30<00:00, 13.50s/it, best loss: 0.21964238103345235]\n",
            "{'lr': 0.0024137336369208263, 'nm': 4.877549655447803}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ1ajodLhR4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70db2bd5-7cef-43ae-ccd6-23a1a3daa35c"
      },
      "source": [
        "eo_progress = run_evolutionary_optimization()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 0, 'lr': 0.0206, 'nm': 2.3, 'eps': 0.3326, 'val_loss': 0.5004, 'reward': 0.6617}: 100%|██████████| 10/10 [02:18<00:00, 13.89s/it]\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 0, 'reward_mean': 0.6923151689180784, 'reward_max': 0.7569686079096618}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 1, 'lr': 0.0206, 'nm': 4.1, 'eps': 0.176, 'val_loss': 0.5832, 'reward': 0.6984}: 100%|██████████| 9/9 [02:05<00:00, 13.95s/it]\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 1, 'reward_mean': 0.7300564713494908, 'reward_max': 0.7534460038120583}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 2, 'lr': 0.0353, 'nm': 2.3, 'eps': 0.3326, 'val_loss': 0.4973, 'reward': 0.6626}: 100%|██████████| 9/9 [02:05<00:00, 13.95s/it]\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 2, 'reward_mean': 0.7306871899130688, 'reward_max': 0.7557390548625252}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 3, 'lr': 0.0402, 'nm': 3.8, 'eps': 0.1885, 'val_loss': 0.5336, 'reward': 0.7073}: 100%|██████████| 9/9 [02:04<00:00, 13.84s/it]\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 3, 'reward_mean': 0.7295607055249926, 'reward_max': 0.7555506264692051}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 4, 'lr': 0.0206, 'nm': 2.0, 'eps': 0.3944, 'val_loss': 0.4933, 'reward': 0.6423}: 100%|██████████| 9/9 [02:04<00:00, 13.84s/it]\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 4, 'reward_mean': 0.7305160926447191, 'reward_max': 0.7642557124915101}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 5, 'lr': 0.0059, 'nm': 3.8, 'eps': 0.1885, 'val_loss': 0.4333, 'reward': 0.7383}: 100%|██████████| 9/9 [02:04<00:00, 13.88s/it]\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 5, 'reward_mean': 0.7453124008784301, 'reward_max': 0.7661512924830864}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 6, 'lr': 0.0304, 'nm': 3.5, 'eps': 0.2047, 'val_loss': 0.564, 'reward': 0.6919}: 100%|██████████| 9/9 [02:03<00:00, 13.75s/it]\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 6, 'reward_mean': 0.7448884226340449, 'reward_max': 0.7633982450772268}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 7, 'lr': 0.0353, 'nm': 4.1, 'eps': 0.176, 'val_loss': 0.7356, 'reward': 0.6589}: 100%|██████████| 9/9 [02:04<00:00, 13.82s/it]\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 7, 'reward_mean': 0.7376926754126129, 'reward_max': 0.7676821222215464}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 8, 'lr': 0.0108, 'nm': 4.4, 'eps': 0.166, 'val_loss': 0.4717, 'reward': 0.7355}: 100%|██████████| 9/9 [02:04<00:00, 13.87s/it]\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 8, 'reward_mean': 0.748433337716076, 'reward_max': 0.764924089273108}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 9, 'lr': 0.0402, 'nm': 4.4, 'eps': 0.166, 'val_loss': 1.1178, 'reward': 0.587}: 100%|██████████| 9/9 [02:03<00:00, 13.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'gen_num': 9, 'reward_mean': 0.7282234614522305, 'reward_max': 0.7659901341604181}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tp5dCA-hVRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ba7671-fe8e-41d8-acac-d9c914c1a937"
      },
      "source": [
        "rl_progress = run_reinforcement_learning_optimization()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [02:19<00:00, 13.93s/it]\n",
            "100%|██████████| 10/10 [02:18<00:00, 13.85s/it]\n",
            "100%|██████████| 10/10 [02:19<00:00, 13.93s/it]\n",
            "100%|██████████| 10/10 [02:20<00:00, 14.05s/it]\n",
            "100%|██████████| 10/10 [02:18<00:00, 13.90s/it]\n",
            "100%|██████████| 10/10 [02:17<00:00, 13.74s/it]\n",
            "100%|██████████| 10/10 [02:20<00:00, 14.01s/it]\n",
            "100%|██████████| 10/10 [02:19<00:00, 13.90s/it]\n",
            "100%|██████████| 10/10 [02:17<00:00, 13.76s/it]\n",
            "100%|██████████| 10/10 [02:18<00:00, 13.84s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo3X-0MDhhGS"
      },
      "source": [
        "## Evaluating the Results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9Y1uQ4blYL1"
      },
      "source": [
        "eo_progress_ext = np.concatenate(eo_progress, 0)\n",
        "rl_progress_ext = np.concatenate(rl_progress, 0)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTmx-7j4hX2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c7a76bb-a4de-426c-e551-1ec8b9989778"
      },
      "source": [
        "print(\"Maximum Reward Achieved by Each Algorithm:\")\n",
        "algorithms = [gs_progress, bo_progress, eo_progress_ext, rl_progress_ext]\n",
        "max_rewards_index = [np.argmax(i.T[-1]) for i in algorithms]\n",
        "max_rewards = pd.DataFrame(np.stack([i[index] for i, index in zip(algorithms, max_rewards_index)]))\n",
        "max_rewards.columns = 'nm, lr, eps, train_loss, val_loss, train_acc, val_acc, reward'.split(', ')\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "print(max_rewards)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum Reward Achieved by Each Algorithm:\n",
            "         nm        lr       eps  train_loss  val_loss  train_acc   val_acc  \\\n",
            "0  4.666667  0.001000  0.158780    0.389207  0.378369    0.88500  0.880313   \n",
            "1  4.877550  0.002414  0.153917    0.368038  0.351870    0.89125  0.884062   \n",
            "2  4.379012  0.003984  0.166633    0.394809  0.372726    0.89000  0.895000   \n",
            "3  4.666667  0.001000  0.158780    0.381342  0.373430    0.88250  0.885000   \n",
            "\n",
            "     reward  \n",
            "0  0.769081  \n",
            "1  0.780358  \n",
            "2  0.767682  \n",
            "3  0.770777  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge6ultJgmO3k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}